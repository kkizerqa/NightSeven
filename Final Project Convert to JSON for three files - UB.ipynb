{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python HL7 to JSON converter\n",
    "MSDS 5023 Information Structures\n",
    "Professor Best\n",
    "Urvish Bhagat\n",
    "October 9, 2015\n",
    "Final Paper\n",
    "\n",
    "\n",
    "We read the msg1.txt file into \"array\"\n",
    "\n",
    "Next, we appened a line break to the end of each line.\n",
    "\n",
    "Then, we updated the array by separating the fields according to the pipe character, \"|\"\n",
    "\n",
    "We then added spaces for the \"^\" character\n",
    "\n",
    "Finally, we printed just the last record in what we believe to be JSON format.\n",
    "\n",
    "The object begins with a {. The rest of the elements are in a JSON array marked by [ and ] on each end. The object ends with a }.\n",
    "\n",
    "We are still working on the loop to pull the fields out of the array for the rest of the rows.\n",
    "\n",
    "Mr. Best: Is the JSON output acceptable once we apply to the rest of the rows?\n",
    "\n",
    "{ ZCS : [ DIS , DISABLED DISABLED GA 30092 , N , NONE , NONE , 08625 ]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON File Structure\n"
     ]
    }
   ],
   "source": [
    "#Urvish Bhagat\n",
    "#copied code from our last class and try to understand the logic.\n",
    "#used Mary's logic.\n",
    "#import pandas as pd\n",
    "#msg1 = pd.read_csv ('/users/urvishbhagat/desktop/msg1.txt')\n",
    "#msg2 = pd.read_csv ('/users/urvishbhagat/desktop/msg2.txt')\n",
    "#msg3 = pd.read_csv ('/users/urvishbhagat/desktop/msg3.txtâ€™)\n",
    "#import numpy as np\n",
    "\n",
    "infile = open('/users/urvishbhagat/desktop/msg1.txt', 'r')  # Open the file for reading.\n",
    "data = infile.read()  # Read the contents of the file.\n",
    "infile.close()  # Close the file since we're done using it.\n",
    "\n",
    "#check to see if the file is valid.\n",
    "if data[0:8] == \"MSH|^~\\\\&\":\n",
    "    print \"JSON File Structure\"\n",
    "else:\n",
    "    print \"Incorrect File\" #Incorrect File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{rec:{MSH1.1.1:MSH}{MSH1.2.1:~\\&}{MSH1.3.1:ABCDE}{MSH1.4.1:201507230021}{MSH1.5.1:ADT}{MSH1.5.2:A08}{MSH1.6.1:CAGTADM.1.10532994}{MSH1.7.1:P}{MSH1.8.1:2.1}{EVN2.1.1:EVN}{EVN2.2.1:A08}{EVN2.3.1:201507230021}{EVN2.4.1:R.CA.NAH}{EVN2.4.2:HALL}{EVN2.4.3:NANCY}{EVN2.4.4:A}{PID3.1.1:PID}{PID3.2.1:1}{PID3.3.1:V000042610}{PID3.4.1:M88604}{PID3.5.1:BARTON}{PID3.5.2:CLINTON}{PID3.5.3:FRANCIS}{PID3.6.1:19510121}{PID3.7.1:M}{PID3.9.1:W}{PID3.10.1:9 E CARTER ST APT A}{PID3.10.2:CARTERSVILLE}{PID3.10.3:GA}{PID3.10.4:30120}{PID3.10.5:USA}{PID3.10.6:BARTOW}{PID3.11.1:(000)000-0000}{PID3.12.1:(000)000-0000}{PID3.13.1:ENG}{PID3.14.1:D}{PID3.15.1:OTH}{PID3.16.1:V07016760770}{PID3.17.1:000-00-0000}{NK14.1.1:NK1}{NK14.2.1:1}{NK14.3.1:POSTEN}{NK14.3.2:BOBBY}{NK14.4.1:OT}{NK14.5.1:102 S.H.E.I.L.D Floating Island}{NK14.5.2:CARTERSVILLE}{NK14.5.3:GA}{NK14.5.4:30120}{NK14.5.5:USA}{NK14.5.6:BARTOW}{NK14.6.1:(000)000-0000}{NK14.7.1:(000)000-0000}{NK15.1.1:NK1}{NK15.2.1:2}{NK15.3.1:POSTEN}{NK15.3.2:BOBBY}{NK15.4.1:OT}{NK15.5.1:102 S.H.E.I.L.D Floating Island}{NK15.5.2:CARTERSVILLE}{NK15.5.3:GA}{NK15.5.4:30120}{NK15.5.5:USA}{NK15.5.6:BARTOW}{NK15.6.1:(000)000-0000}{NK15.7.1:(000)000-0000}{PV16.1.1:PV1}{PV16.2.1:1}{PV16.3.1:E}{PV16.4.1:V.ER}{PV16.5.1:EM}{PV16.6.1:WILSON}{PV16.6.2:Wade}{PV16.6.3:Deadpool}{PV16.6.4:MD}{PV16.7.1:.SELF}{PV16.7.2:Referred}{PV16.7.3:Self}{PV16.8.1:MARKO}{PV16.8.2:Cain}{PV16.8.3:Bighelmet}{PV16.8.4:MD}{PV16.9.1:ER}{PV16.10.1:PR}{PV16.11.1:WI}{PV16.12.1:N}{PV16.13.1:ER}{PV16.14.1:03}{PV16.15.1:ABCDE}{PV16.16.1:back pain}{PV16.17.1:REG}{PV16.18.1:201507222358}{AL17.1.1:AL1}{AL17.2.1:1}{AL17.3.1:DA}{AL17.4.1:F000004181}{AL17.4.2:tramadol HCl}{AL17.4.3:From ULTRAM}{AL17.5.1:MO}{AL17.6.1:JERKING}{AL17.7.1:20140525}{ACC8.1.1:ACC}{ACC8.2.1:20150722}{ACC8.3.1:11}{GT19.1.1:GT1}{GT19.2.1:1}{GT19.3.1:BARTON}{GT19.3.2:CLINTON}{GT19.3.3:FRANCIS}{GT19.4.1:9 S.H.E.I.L.D Training Facility}{GT19.4.2:CARTERSVILLE}{GT19.4.3:GA}{GT19.4.4:30120}{GT19.4.5:USA}{GT19.4.6:BARTOW}{GT19.5.1:(000)000-0000}{GT19.6.1:19510121}{GT19.7.1:M}{GT19.8.1:SA}{GT19.9.1:000-00-0000}{GT19.10.1:DISABLED}{GT19.11.1:DISABLED}{GT19.11.2:DISABLED}{GT19.11.3:GA}{GT19.11.4:30092}{GT19.12.1:(000)000-0000}{GT19.13.1:N}{GT110.1.1:GT1}{GT110.2.1:2}{IN111.1.1:IN1}{IN111.2.1:1}{IN111.3.1:MDGA001}{IN111.4.1:MEDICAID GA}{IN111.5.1:PO BOX 5000}{IN111.5.2:MCRAE}{IN111.5.3:GA}{IN111.5.4:31055}{IN111.5.5:USA}{IN111.6.1:(000)000-0000}{IN111.7.1:MEDICAID}{IN111.8.1:20150722}{IN111.9.1:JACOBS}{IN111.9.2:DANNY}{IN111.9.3:S}{IN111.10.1:01}{IN111.11.1:19510121}{IN111.12.1:111441591411}{IN111.13.1:M}{ZMR12.1.1:ZMR}{ZMR12.2.1:1}{ZMR12.3.1:GH00426357~IL00806247~M000103533}{ZCD13.1.1:ZCD}{ZCD13.2.1:1}{ZCD13.3.1:ETHNICITY}{ZCD13.3.2:ETHNICITY}{ZCD13.3.3:2}{ZCD14.1.1:ZCD}{ZCD14.2.1:2}{ZCD14.3.1:Z.ADDLRACE}{ZCD14.3.2:ADDITIONAL RACE}{ZCD14.3.3:W}{ZIN15.1.1:ZIN}{ZIN15.2.1:1}{ZIN15.3.1:SP}{ZIN15.4.1:GHP}{ZIN15.5.1:Y}{ZIN15.6.1:20150723}{ZIN15.7.1:PPI}{ZIN15.8.1:N}{ZIN15.9.1:MDGA001}{ZCS16.1.1:ZCS}{ZCS16.2.1:DIS}{ZCS16.3.1:DISABLED}{ZCS16.3.2:DISABLED}{ZCS16.3.3:GA}{ZCS16.3.4:30092}{ZCS16.4.1:N}{ZCS16.5.1:NONE}{ZCS16.6.1:NONE}{ZCS16.7.1:08625}}\n"
     ]
    }
   ],
   "source": [
    "#import in an multi dimensional array.\n",
    "\n",
    "segs = str.split(data,'\\r\\n') #end of the line\n",
    "json_str = '{' + 'rec:'       # add first {\n",
    "for index, seg in enumerate(segs): \n",
    "    seg_string = seg[0:3] # store the first three letters of the line\n",
    "    #print seg_string\n",
    "    fields = str.split(seg, '|') #split the line\n",
    "    stripfield = filter(None,fields)\n",
    "    #print stripfield\n",
    "    for index1, field in enumerate(stripfield):\n",
    "        compons = str.split(field,'^')\n",
    "        #print index\n",
    "        stripcomps = filter(None,compons)                       \n",
    "        #print compons\n",
    "        for index2, subcomp in enumerate(stripcomps):\n",
    "            subcomps = str.split(subcomp,'~')\n",
    "            #print subcomps\n",
    "            #Stripcomps = filter(None,subcomps)\n",
    "            #print index,index1,index2,subcomps\n",
    "            if(subcomp != ''):\n",
    "                json_str = json_str + '{' + seg_string + str(index + 1) + '.' + str(index1 + 1) + '.' + str(index2 + 1) + ':' + subcomp + '}'\n",
    "print json_str + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON File Structure\n",
      "{rec:{MSH1.1.1:MSH}{MSH1.2.1:~\\&}{MSH1.3.1:ABCDE}{MSH1.4.1:201507221833}{MSH1.5.1:ADT}{MSH1.5.2:A08}{MSH1.6.1:CAGTADM.1.10532250}{MSH1.7.1:P}{MSH1.8.1:2.1}{EVN2.1.1:EVN}{EVN2.2.1:A08}{EVN2.3.1:201507221833}{EVN2.4.1:R.HIM.CLV}{EVN2.4.2:VEALS}{EVN2.4.3:CHENEKA}{EVN2.4.4:L}{PID3.1.1:PID}{PID3.2.1:1}{PID3.3.1:V000303465}{PID3.4.1:V256537}{PID3.5.1:ROMANOVA}{PID3.5.2:NATALIA}{PID3.5.3:ALIANOVA}{PID3.6.1:19961213}{PID3.7.1:F}{PID3.9.1:W}{PID3.10.1:40 page avant impression}{PID3.10.2:CARTERSVILLE}{PID3.10.3:GA}{PID3.10.4:30120}{PID3.10.5:USA}{PID3.10.6:BARTOW}{PID3.11.1:(000)000-0000}{PID3.12.1:(000)000-0000}{PID3.13.1:ENG}{PID3.14.1:S}{PID3.15.1:NON}{PID3.16.1:V07016754636}{PID3.17.1:000-00-0000}{PV14.1.1:PV1}{PV14.2.1:1}{PV14.3.1:E}{PV14.4.1:V.OBED}{PV14.5.1:EM}{PV14.6.1:STRANGE}{PV14.6.2:STEPHEN}{PV14.6.3:VINCENT}{PV14.6.4:MD}{PV14.7.1:STRANGE}{PV14.7.2:STEPHEN}{PV14.7.3:VINCENT}{PV14.7.4:MD}{PV14.8.1:STRANGE}{PV14.8.2:STEPHEN}{PV14.8.3:VINCENT}{PV14.8.4:MD}{PV14.9.1:OBED}{PV14.10.1:CR}{PV14.11.1:WI}{PV14.12.1:N}{PV14.13.1:ER}{PV14.14.1:03}{PV14.15.1:HOM}{PV14.16.1:ABCDE}{PV14.17.1:CONTRACTIONS}{PV14.18.1:DEP}{PV14.19.1:201507202309}{PV14.20.1:201507210150}{ACC5.1.1:ACC}{ACC5.2.1:20141030}{ACC5.3.1:10}{GT16.1.1:GT1}{GT16.2.1:1}{GT16.3.1:ROMANOVA}{GT16.3.2:NATALIA}{GT16.3.3:ALIANOVA}{GT16.4.1:40 page avant impression}{GT16.4.2:CARTERSVILLE}{GT16.4.3:GA}{GT16.4.4:30120}{GT16.4.5:USA}{GT16.4.6:BARTOW}{GT16.5.1:(000)000-0000}{GT16.6.1:19961213}{GT16.7.1:F}{GT16.8.1:SA}{GT16.9.1:000-00-0000}{GT16.10.1:UNEMPLOYED}{GT16.11.1:UNEMPLOYED}{GT16.11.2:UNEMPLOYED}{GT16.11.3:GA}{GT16.11.4:30092}{GT16.12.1:(000)000-0000}{GT16.13.1:U}{GT17.1.1:GT1}{GT17.2.1:2}{IN18.1.1:IN1}{IN18.2.1:1}{IN18.3.1:MDGA001}{IN18.4.1:MEDICAID GA}{IN18.5.1:PO BOX 105204}{IN18.5.2:TUCKER}{IN18.5.3:GA}{IN18.5.4:30085-5204}{IN18.5.5:USA}{IN18.6.1:(000)000-0000}{IN18.7.1:MEDICAID}{IN18.8.1:ROMANOVA}{IN18.8.2:NATALIA}{IN18.8.3:ALIANOVA}{IN18.9.1:01}{IN18.10.1:19961213}{IN18.11.1:8161779686}{IN18.12.1:F}{ZCD9.1.1:ZCD}{ZCD9.2.1:1}{ZCD9.3.1:ETHNICITY}{ZCD9.3.2:ETHNICITY}{ZCD9.3.3:2}{ZIN10.1.1:ZIN}{ZIN10.2.1:1}{ZIN10.3.1:SP}{ZIN10.4.1:HP - UB04 CLAIMS}{ZIN10.5.1:N}{ZIN10.6.1:N}{ZIN10.7.1:MDGA001}{ZCS11.1.1:ZCS}{ZCS11.2.1:UEMP}{ZCS11.3.1:UNEMPLOYED}{ZCS11.3.2:UNEMPLOYED}{ZCS11.3.3:GA}{ZCS11.3.4:30092}{ZCS11.4.1:U}{ZCS11.5.1:NONE}{ZCS11.6.1:NONE}{ZCS11.7.1:08625}}\n"
     ]
    }
   ],
   "source": [
    "infile = open('/users/urvishbhagat/desktop/msg2.txt', 'r')  # Open the file for reading.\n",
    "data = infile.read()  # Read the contents of the file.\n",
    "infile.close()  # Close the file since we're done using it.\n",
    "\n",
    "#check to see if the file is valid.\n",
    "if data[0:8] == \"MSH|^~\\\\&\":\n",
    "    print \"JSON File Structure\"\n",
    "else:\n",
    "    print \"Incorrect File\" #Incorrect File\n",
    "#import in an multi dimensional array.\n",
    "\n",
    "segs = str.split(data,'\\r\\n') #end of the line\n",
    "json_str = '{' + 'rec:'       # add first {\n",
    "for index, seg in enumerate(segs): \n",
    "    seg_string = seg[0:3] # store the first three letters of the line\n",
    "    #print seg_string\n",
    "    fields = str.split(seg, '|') #split the line\n",
    "    stripfield = filter(None,fields)\n",
    "    #print stripfield\n",
    "    for index1, field in enumerate(stripfield):\n",
    "        compons = str.split(field,'^')\n",
    "        #print index\n",
    "        stripcomps = filter(None,compons)                       \n",
    "        #print compons\n",
    "        for index2, subcomp in enumerate(stripcomps):\n",
    "            subcomps = str.split(subcomp,'~')\n",
    "            #print subcomps\n",
    "            #Stripcomps = filter(None,subcomps)\n",
    "            #print index,index1,index2,subcomps\n",
    "            if(subcomp != ''):\n",
    "                json_str = json_str + '{' + seg_string + str(index + 1) + '.' + str(index1 + 1) + '.' + str(index2 + 1) + ':' + subcomp + '}'\n",
    "print json_str + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON File Structure\n",
      "{rec:{MSH1.1.1:MSH}{MSH1.2.1:~\\&}{MSH1.3.1:ABCDE}{MSH1.4.1:201507230002}{MSH1.5.1:ADT}{MSH1.5.2:A03}{MSH1.6.1:CAGTADM.1.10532923}{MSH1.7.1:P}{MSH1.8.1:2.1}{EVN2.1.1:EVN}{EVN2.2.1:A03}{EVN2.3.1:201507230001}{EVN2.4.1:MIDNT RUN}{PID3.1.1:PID}{PID3.2.1:1}{PID3.3.1:V000027071}{PID3.4.1:V24686}{PID3.5.1:BANNER}{PID3.5.2:ROBERT}{PID3.5.3:BRUCE}{PID3.6.1:19820215}{PID3.7.1:M}{PID3.9.1:W}{PID3.10.1:31 simplement du faux }{PID3.10.2:CARTERSVILLE}{PID3.10.3:GA}{PID3.10.4:30121}{PID3.10.5:USA}{PID3.10.6:BARTOW}{PID3.11.1:(000)000-0000}{PID3.12.1:(000)000-0000}{PID3.13.1:ENG}{PID3.14.1:S}{PID3.15.1:CHR}{PID3.16.1:V07016746578}{PID3.17.1:000-00-0000}{PV14.1.1:PV1}{PV14.2.1:1}{PV14.3.1:O}{PV14.4.1:V.SRG}{PV14.5.1:EL}{PV14.6.1:GAMMA}{PV14.6.2:RAE}{PV14.6.3:Jr}{PV14.6.4:MD}{PV14.7.1:GAMMA}{PV14.7.2:RAE}{PV14.7.3:Jr}{PV14.7.4:MD}{PV14.8.1:.NO PCP}{PV14.8.2:Physician}{PV14.8.3:No}{PV14.8.4:Primary or Family}{PV14.9.1:SURG}{PV14.10.1:CR}{PV14.11.1:N}{PV14.12.1:SDC}{PV14.13.1:01}{PV14.14.1:HOM}{PV14.15.1:ABCDE}{PV14.16.1:URETHERAL STRICTURE DISEASE      CPT:  52276,52341}{PV14.17.1:DEP}{PV14.18.1:201507220855}{PV14.19.1:201507220855}{AL15.1.1:AL1}{AL15.2.1:1}{AL15.3.1:DA}{AL15.4.1:F001000476}{AL15.4.2:Penicillins}{AL15.4.3:PENICILLINS}{AL15.5.1:SV}{AL15.6.1:RASH,ITCH,THROAT SWELLING}{AL15.7.1:20150720}{AL16.1.1:AL1}{AL16.2.1:2}{AL16.3.1:DA}{AL16.4.1:F006001545}{AL16.4.2:morphine}{AL16.4.3:MORPHINE}{AL16.5.1:SV}{AL16.6.1:RASH,ITCH}{AL16.7.1:20150720}{AL17.1.1:AL1}{AL17.2.1:3}{AL17.3.1:DA}{AL17.4.1:F006004180}{AL17.4.2:tramadol}{AL17.4.3:TRAMADOL}{AL17.5.1:SV}{AL17.6.1:MAKES ILL / VIOLENT}{AL17.7.1:20150721}{AL18.1.1:AL1}{AL18.2.1:4}{AL18.3.1:DA}{AL18.4.1:F006004807}{AL18.4.2:ondansetron}{AL18.4.3:From ZOFRAN (AS HYDROCHLORIDE)}{AL18.5.1:SV}{AL18.6.1:MAKE ILL / VIOLENT}{AL18.7.1:20150721}{AL19.1.1:AL1}{AL19.2.1:5}{AL19.3.1:DA}{AL19.4.1:F006004812}{AL19.4.2:ketorolac}{AL19.4.3:From TORADOL}{AL19.5.1:SV}{AL19.6.1:MAKES ME MEAN}{AL19.7.1:20150720}{ACC10.1.1:ACC}{ACC10.2.1:20150717}{ACC10.3.1:11}{GT111.1.1:GT1}{GT111.2.1:1}{GT111.3.1:BANNER}{GT111.3.2:ROBERT}{GT111.3.3:BRUCE}{GT111.4.1:31 simplement du faux}{GT111.4.2:CARTERSVILLE}{GT111.4.3:GA}{GT111.4.4:30121}{GT111.4.5:USA}{GT111.4.6:BARTOW}{GT111.5.1:(000)000-0000}{GT111.6.1:19820215}{GT111.7.1:M}{GT111.8.1:SA}{GT111.9.1:000-00-0000}{GT111.10.1:DISABLED}{GT111.11.1:DISABLED}{GT111.11.2:DISABLED}{GT111.11.3:GA}{GT111.11.4:30092}{GT111.12.1:(000)000-0000}{GT111.13.1:N}{GT112.1.1:GT1}{GT112.2.1:2}{IN113.1.1:IN1}{IN113.2.1:1}{IN113.3.1:MACP051}{IN113.4.1:MEDICARE A   B}{IN113.5.1:CLAIMS DEPT}{IN113.5.2:PO BOX 1602}{IN113.5.3:OMAHA}{IN113.5.4:NE}{IN113.5.5:68101}{IN113.5.6:USA}{IN113.6.1:(000)000-0000}{IN113.7.1:20110601}{IN113.8.1:NR/S}{IN113.8.2:20150717}{IN113.9.1:BANNER}{IN113.9.2:ROBERT}{IN113.9.3:BRUCE}{IN113.10.1:01}{IN113.11.1:19820215}{IN113.12.1:253494993A}{IN113.13.1:M}{IN114.1.1:IN1}{IN114.2.1:2}{IN114.3.1:MDGA002}{IN114.4.1:MEDICAID GA SECONDARY}{IN114.5.1:PO BOX 105204}{IN114.5.2:TUCKER}{IN114.5.3:GA}{IN114.5.4:30085-5204}{IN114.5.5:USA}{IN114.6.1:(000)000-0000}{IN114.7.1:MEDICAID}{IN114.8.1:20150717}{IN114.9.1:BANNER}{IN114.9.2:ROBERT}{IN114.9.3:BRUCE}{IN114.10.1:01}{IN114.11.1:19820215}{IN114.12.1:111310503248}{IN114.13.1:M}{ZMR15.1.1:ZMR}{ZMR15.2.1:1}{ZMR15.3.1:IL00799251~M000526547}{ZCD16.1.1:ZCD}{ZCD16.2.1:1}{ZCD16.3.1:ETHNICITY}{ZCD16.3.2:ETHNICITY}{ZCD16.3.3:2}{ZIN17.1.1:ZIN}{ZIN17.2.1:1}{ZIN17.3.1:SP}{ZIN17.4.1:WPS MEDICARE PART A}{ZIN17.5.1:Y}{ZIN17.6.1:20150720}{ZIN17.7.1:PPI}{ZIN17.8.1:Y}{ZIN17.9.1:PAYOR/MCARE/SYSTEM}{ZIN17.10.1:MACP051}{ZIN18.1.1:ZIN}{ZIN18.2.1:2}{ZIN18.3.1:SP}{ZIN18.4.1:HP - UBO4 CLAIMS}{ZIN18.5.1:Y}{ZIN18.6.1:20150717}{ZIN18.7.1:PPB}{ZIN18.8.1:N}{ZIN18.9.1:MDGA002}{ZCN19.1.1:ZCN}{ZCN19.2.1:1}{ZCN19.3.1:201507201346}{ZCN19.4.1:R.CA.BSF}{ZCN19.5.1:MN PASSED}{ZCN20.1.1:ZCN}{ZCN20.2.1:2}{ZCN20.3.1:201507201346}{ZCN20.4.1:R.CA.BSF}{ZCN20.5.1:DX 598.9}{ZCN21.1.1:ZCN}{ZCN21.2.1:3}{ZCN21.3.1:201507201346}{ZCN21.4.1:R.CA.BSF}{ZCN21.5.1:CPT 52341 52276}{ZCS22.1.1:ZCS}{ZCS22.2.1:DIS}{ZCS22.3.1:DISABLED}{ZCS22.3.2:DISABLED}{ZCS22.3.3:GA}{ZCS22.3.4:30092}{ZCS22.4.1:N}{ZCS22.5.1:DECLINED}{ZCS22.6.1:DECLINED}{ZCS22.7.1:08625}}\n"
     ]
    }
   ],
   "source": [
    "infile = open('/users/urvishbhagat/desktop/msg3.txt', 'r')  # Open the file for reading.\n",
    "data = infile.read()  # Read the contents of the file.\n",
    "infile.close()  # Close the file since we're done using it.\n",
    "\n",
    "#check to see if the file is valid.\n",
    "if data[0:8] == \"MSH|^~\\\\&\":\n",
    "    print \"JSON File Structure\"\n",
    "else:\n",
    "    print \"Incorrect File\" #Incorrect File\n",
    "#import in an multi dimensional array.\n",
    "\n",
    "segs = str.split(data,'\\r\\n') #end of the line\n",
    "json_str = '{' + 'rec:'       # add first {\n",
    "for index, seg in enumerate(segs): \n",
    "    seg_string = seg[0:3] # store the first three letters of the line\n",
    "    #print seg_string\n",
    "    fields = str.split(seg, '|') #split the line\n",
    "    stripfield = filter(None,fields)\n",
    "    #print stripfield\n",
    "    for index1, field in enumerate(stripfield):\n",
    "        compons = str.split(field,'^')\n",
    "        #print index\n",
    "        stripcomps = filter(None,compons)                       \n",
    "        #print compons\n",
    "        for index2, subcomp in enumerate(stripcomps):\n",
    "            subcomps = str.split(subcomp,'~')\n",
    "            #print subcomps\n",
    "            #Stripcomps = filter(None,subcomps)\n",
    "            #print index,index1,index2,subcomps\n",
    "            if(subcomp != ''):\n",
    "                json_str = json_str + '{' + seg_string + str(index + 1) + '.' + str(index1 + 1) + '.' + str(index2 + 1) + ':' + subcomp + '}'\n",
    "print json_str + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
