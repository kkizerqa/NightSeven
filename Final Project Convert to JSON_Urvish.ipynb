{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python HL7 to JSON converter\n",
    "MSDS 5023 Information Structures\n",
    "Professor Best\n",
    "Urvish Bhagat\n",
    "October 9, 2015\n",
    "Final Paper\n",
    "\n",
    "\n",
    "We read the msg1.txt file into \"array\"\n",
    "\n",
    "Next, we appened a line break to the end of each line.\n",
    "\n",
    "Then, we updated the array by separating the fields according to the pipe character, \"|\"\n",
    "\n",
    "We then added spaces for the \"^\" character\n",
    "\n",
    "Finally, we printed just the last record in what we believe to be JSON format.\n",
    "\n",
    "The object begins with a {. The rest of the elements are in a JSON array marked by [ and ] on each end. The object ends with a }.\n",
    "\n",
    "We are still working on the loop to pull the fields out of the array for the rest of the rows.\n",
    "\n",
    "Mr. Best: Is the JSON output acceptable once we apply to the rest of the rows?\n",
    "\n",
    "{ ZCS : [ DIS , DISABLED DISABLED GA 30092 , N , NONE , NONE , 08625 ]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON File Structure\n"
     ]
    }
   ],
   "source": [
    "#Urvish Bhagat\n",
    "#Import section\n",
    "#import os\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib as mpl\n",
    "#copied code from our last class and try to understand the logic.\n",
    "\n",
    "# Read in the health data\n",
    "msg1 = pd.read_csv ('/users/urvishbhagat/desktop/msg1.txt')\n",
    "#msg2 = pd.read_csv ('/users/urvishbhagat/desktop/msg2.txt')\n",
    "#msg3 = pd.read_csv ('/users/urvishbhagat/desktop/msg3.txtâ€™)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "infile = open('/users/urvishbhagat/desktop/msg1.txt', 'r')  # Open the file for reading.\n",
    "\n",
    "data = infile.read()  # Read the contents of the file.\n",
    "\n",
    "infile.close()  # Close the file since we're done using it.\n",
    "\n",
    "if data[0:8] == \"MSH|^~\\\\&\":\n",
    "    print \"JSON File Structure\"\n",
    "else:\n",
    "    print \"Incorrect File\" #Incorrect File\n",
    "import sys\n",
    "\n",
    "#print \"filename count \", len (sys.argv)\n",
    "\n",
    "#print \"filename: \", str(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{rec:{MSH1.1.1:MSH}{MSH1.2.1:~\\&}{MSH1.3.1:ABCDE}{MSH1.4.1:201507230021}{MSH1.5.1:ADT}{MSH1.5.2:A08}{MSH1.6.1:CAGTADM.1.10532994}{MSH1.7.1:P}{MSH1.8.1:2.1}{EVN2.1.1:EVN}{EVN2.2.1:A08}{EVN2.3.1:201507230021}{EVN2.4.1:R.CA.NAH}{EVN2.4.2:HALL}{EVN2.4.3:NANCY}{EVN2.4.4:A}{PID3.1.1:PID}{PID3.2.1:1}{PID3.3.1:V000042610}{PID3.4.1:M88604}{PID3.5.1:BARTON}{PID3.5.2:CLINTON}{PID3.5.3:FRANCIS}{PID3.6.1:19510121}{PID3.7.1:M}{PID3.9.1:W}{PID3.10.1:9 E CARTER ST APT A}{PID3.10.2:CARTERSVILLE}{PID3.10.3:GA}{PID3.10.4:30120}{PID3.10.5:USA}{PID3.10.6:BARTOW}{PID3.11.1:(000)000-0000}{PID3.12.1:(000)000-0000}{PID3.13.1:ENG}{PID3.14.1:D}{PID3.15.1:OTH}{PID3.16.1:V07016760770}{PID3.17.1:000-00-0000}{NK14.1.1:NK1}{NK14.2.1:1}{NK14.3.1:POSTEN}{NK14.3.2:BOBBY}{NK14.4.1:OT}{NK14.5.1:102 S.H.E.I.L.D Floating Island}{NK14.5.2:CARTERSVILLE}{NK14.5.3:GA}{NK14.5.4:30120}{NK14.5.5:USA}{NK14.5.6:BARTOW}{NK14.6.1:(000)000-0000}{NK14.7.1:(000)000-0000}{NK15.1.1:NK1}{NK15.2.1:2}{NK15.3.1:POSTEN}{NK15.3.2:BOBBY}{NK15.4.1:OT}{NK15.5.1:102 S.H.E.I.L.D Floating Island}{NK15.5.2:CARTERSVILLE}{NK15.5.3:GA}{NK15.5.4:30120}{NK15.5.5:USA}{NK15.5.6:BARTOW}{NK15.6.1:(000)000-0000}{NK15.7.1:(000)000-0000}{PV16.1.1:PV1}{PV16.2.1:1}{PV16.3.1:E}{PV16.4.1:V.ER}{PV16.5.1:EM}{PV16.6.1:WILSON}{PV16.6.2:Wade}{PV16.6.3:Deadpool}{PV16.6.4:MD}{PV16.7.1:.SELF}{PV16.7.2:Referred}{PV16.7.3:Self}{PV16.8.1:MARKO}{PV16.8.2:Cain}{PV16.8.3:Bighelmet}{PV16.8.4:MD}{PV16.9.1:ER}{PV16.10.1:PR}{PV16.11.1:WI}{PV16.12.1:N}{PV16.13.1:ER}{PV16.14.1:03}{PV16.15.1:ABCDE}{PV16.16.1:back pain}{PV16.17.1:REG}{PV16.18.1:201507222358}{AL17.1.1:AL1}{AL17.2.1:1}{AL17.3.1:DA}{AL17.4.1:F000004181}{AL17.4.2:tramadol HCl}{AL17.4.3:From ULTRAM}{AL17.5.1:MO}{AL17.6.1:JERKING}{AL17.7.1:20140525}{ACC8.1.1:ACC}{ACC8.2.1:20150722}{ACC8.3.1:11}{GT19.1.1:GT1}{GT19.2.1:1}{GT19.3.1:BARTON}{GT19.3.2:CLINTON}{GT19.3.3:FRANCIS}{GT19.4.1:9 S.H.E.I.L.D Training Facility}{GT19.4.2:CARTERSVILLE}{GT19.4.3:GA}{GT19.4.4:30120}{GT19.4.5:USA}{GT19.4.6:BARTOW}{GT19.5.1:(000)000-0000}{GT19.6.1:19510121}{GT19.7.1:M}{GT19.8.1:SA}{GT19.9.1:000-00-0000}{GT19.10.1:DISABLED}{GT19.11.1:DISABLED}{GT19.11.2:DISABLED}{GT19.11.3:GA}{GT19.11.4:30092}{GT19.12.1:(000)000-0000}{GT19.13.1:N}{GT110.1.1:GT1}{GT110.2.1:2}{IN111.1.1:IN1}{IN111.2.1:1}{IN111.3.1:MDGA001}{IN111.4.1:MEDICAID GA}{IN111.5.1:PO BOX 5000}{IN111.5.2:MCRAE}{IN111.5.3:GA}{IN111.5.4:31055}{IN111.5.5:USA}{IN111.6.1:(000)000-0000}{IN111.7.1:MEDICAID}{IN111.8.1:20150722}{IN111.9.1:JACOBS}{IN111.9.2:DANNY}{IN111.9.3:S}{IN111.10.1:01}{IN111.11.1:19510121}{IN111.12.1:111441591411}{IN111.13.1:M}{ZMR12.1.1:ZMR}{ZMR12.2.1:1}{ZMR12.3.1:GH00426357~IL00806247~M000103533}{ZCD13.1.1:ZCD}{ZCD13.2.1:1}{ZCD13.3.1:ETHNICITY}{ZCD13.3.2:ETHNICITY}{ZCD13.3.3:2}{ZCD14.1.1:ZCD}{ZCD14.2.1:2}{ZCD14.3.1:Z.ADDLRACE}{ZCD14.3.2:ADDITIONAL RACE}{ZCD14.3.3:W}{ZIN15.1.1:ZIN}{ZIN15.2.1:1}{ZIN15.3.1:SP}{ZIN15.4.1:GHP}{ZIN15.5.1:Y}{ZIN15.6.1:20150723}{ZIN15.7.1:PPI}{ZIN15.8.1:N}{ZIN15.9.1:MDGA001}{ZCS16.1.1:ZCS}{ZCS16.2.1:DIS}{ZCS16.3.1:DISABLED}{ZCS16.3.2:DISABLED}{ZCS16.3.3:GA}{ZCS16.3.4:30092}{ZCS16.4.1:N}{ZCS16.5.1:NONE}{ZCS16.6.1:NONE}{ZCS16.7.1:08625}}\n"
     ]
    }
   ],
   "source": [
    "msg = open('/users/urvishbhagat/desktop/msg1.txt', mode = 'r')\n",
    "\n",
    "#import in an aaray\n",
    "\n",
    "segs = str.split(data,'\\r\\n')\n",
    "json_str = '{' + 'rec:'\n",
    "for index, seg in enumerate(segs):\n",
    "    seg_string = seg[0:3]\n",
    "    #print seg_string\n",
    "    fields = str.split(seg, '|')\n",
    "    stripfield = filter(None,fields)\n",
    "    #print stripfield\n",
    "    for index1, field in enumerate(stripfield):\n",
    "        compons = str.split(field,'^')\n",
    "        #print index\n",
    "        stripcomps = filter(None,compons)                       \n",
    "        #print compons\n",
    "        for index2, subcomp in enumerate(stripcomps):\n",
    "            subcomps = str.split(subcomp,'~')\n",
    "            #print subcomps\n",
    "            #Stripcomps = filter(None,subcomps)\n",
    "            #print index,index1,index2,subcomps\n",
    "            if(subcomp != ''):\n",
    "                json_str = json_str + '{' + seg_string + str(index + 1) + '.' + str(index1 + 1) + '.' + str(index2 + 1) + ':' + subcomp + '}'\n",
    "print json_str + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}